# üìÇ NLP Pipelines

This folder contains **9 essential NLP preprocessing pipelines**, each implemented as a simple and practical Jupyter Notebook.

Every notebook includes:
- A short Markdown overview  
- One or two example code blocks  
- A minimal demonstration of the concept  

These notebooks help beginners understand the core steps of Natural Language Processing (NLP).

---

## üìò List of Pipelines

### **1Ô∏è‚É£ Text Cleaning**
**Notebook:** `text_cleaning.ipynb`  
Includes:
- Lowercasing  
- Removing punctuation  
- Removing numbers  
- Removing special characters  

---

### **2Ô∏è‚É£ Tokenization**
**Notebook:** `tokenization.ipynb`  
Includes:
- Word tokenization  
- Sentence tokenization  
- NLTK tokenizers  

---

### **3Ô∏è‚É£ Stopwords Removal**
**Notebook:** `stopwords_removal.ipynb`  
Includes:
- Removing English stopwords using NLTK  
- Basic preprocessing  

---

### **4Ô∏è‚É£ Stemming & Lemmatization**
**Notebook:** `stemming_lemmatization.ipynb`  
Includes:
- Porter Stemming  
- WordNet Lemmatization  

---

### **5Ô∏è‚É£ N-grams**
**Notebook:** `N-grams.ipynb`  
Includes:
- Unigrams  
- Bigrams  
- Trigrams  
- Using `CountVectorizer(ngram_range)`  

---

### **6Ô∏è‚É£ Bag of Words (BoW)**
**Notebook:** `Bag_of_words.ipynb`  
Includes:
- Vocabulary extraction  
- Text-to-count vector conversion  

---

### **7Ô∏è‚É£ TF-IDF**
**Notebook:** `TFIDF.ipynb`  
Includes:
- TF-IDF vectorization  
- Feature names + numeric matrix  

---

### **8Ô∏è‚É£ Word Embeddings**
**Notebook:** `word_embeddings.ipynb`  
Includes:
- Training a small Word2Vec model (Gensim)  
- Viewing word vectors  

---

### **9Ô∏è‚É£ Word Sense Disambiguation (WSD)**
**Notebook:** `WSD.ipynb`  
Includes:
- Lesk algorithm  
- Selecting word meaning based on context  

---

##  üìå How to Run
1. Install requirements using the main repository `requirements.ipynb`.  
2. Open any notebook in Jupyter Notebook/Jupyter Lab.  
3. Run all cells to see each pipeline in action. 

