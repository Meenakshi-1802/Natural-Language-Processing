{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ddc47b-23ec-45a4-8e96-c6b8c9ae8c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded CSV:\n",
      "                                           text\n",
      "0                 I love programming in Python.\n",
      "1               AI is the future of technology.\n",
      "2          Data Science is exciting and useful.\n",
      "3       Natural Language Processing is amazing.\n",
      "4  Machine Learning can solve complex problems.\n",
      "\n",
      " POS Features Extracted:\n",
      "   PRP$  VBG  FW  VB  POS  ''  VBP  VBN  JJ  WP  ...  IN  WP$  MD  NNPS  --  \\\n",
      "0     0    1   0   0    0   0    1    0   0   0  ...   1    0   0     0   0   \n",
      "1     0    0   0   0    0   0    0    0   0   0  ...   1    0   0     0   0   \n",
      "2     0    1   0   0    0   0    0    0   1   0  ...   0    0   0     0   0   \n",
      "3     0    0   0   0    0   0    0    0   2   0  ...   0    0   0     0   0   \n",
      "4     0    0   0   1    0   0    0    0   1   0  ...   0    0   1     0   0   \n",
      "\n",
      "   JJS  JJR  SYM  UH  WDT  \n",
      "0    0    0    0   0    0  \n",
      "1    0    0    0   0    0  \n",
      "2    0    0    0   0    0  \n",
      "3    0    0    0   0    0  \n",
      "4    0    0    0   0    0  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from nltk.data import load\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "#  Download NLTK resources (first time only)\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('tagsets')\n",
    "\n",
    "#  Step 1: Ensure CSV exists\n",
    "# Go one folder up from .ipynb_checkpoints â†’ NLP\n",
    "base_folder = os.path.join(os.getcwd(), \"..\", \"data\")\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(base_folder, \"data.csv\")\n",
    "\n",
    "# If CSV does not exist, create it automatically\n",
    "if not os.path.exists(csv_path):\n",
    "    sample_data = pd.DataFrame({\n",
    "        'text': [\n",
    "            \"I love programming in Python.\",\n",
    "            \"AI is the future of technology.\",\n",
    "            \"Data Science is exciting and useful.\",\n",
    "            \"Natural Language Processing is amazing.\",\n",
    "            \"Machine Learning can solve complex problems.\"\n",
    "        ]\n",
    "    })\n",
    "    sample_data.to_csv(csv_path, index=False)\n",
    "    print(\" data.csv created successfully!\")\n",
    "\n",
    "#  Step 2: Load the CSV safely\n",
    "data = pd.read_csv(csv_path, header=0)\n",
    "print(\" Loaded CSV:\")\n",
    "print(data.head())\n",
    "\n",
    "#  Step 3: POS Tagging Functions\n",
    "def get_tagsets():\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "    return list(tagdict.keys())\n",
    "\n",
    "def get_pos_occurrence_freq(df, tag_list):\n",
    "    feature_dict = {tag: [] for tag in tag_list}\n",
    "    \n",
    "    for sentence in df['text']:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        counts = Counter(tag for word, tag in pos_tags)\n",
    "        \n",
    "        for tag in tag_list:\n",
    "            feature_dict[tag].append(counts.get(tag, 0))\n",
    "    \n",
    "    return pd.DataFrame(feature_dict)\n",
    "\n",
    "#  Step 4: Run POS feature extraction\n",
    "tag_list = get_tagsets()\n",
    "feature_df = get_pos_occurrence_freq(data, tag_list)\n",
    "\n",
    "print(\"\\n POS Features Extracted:\")\n",
    "print(feature_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6282a-781f-42f6-88c7-218c7bd1430c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
